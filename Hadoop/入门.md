



## 第1章 大数据简介

### 1.1 简介

大数据(Big Data): 指无法在一定时间范围内用常规软件工具进行捕捉,管理和处理的数据集合,是需要新处理模式才能具有更强的决策力,洞察发现力和流程优化能力的海量,高增长率和多样化的信息资产.

### 1.2 大数据特点

1.  Volume(大量)

   截止目前,人类生产的所有印刷材料的数据量是200PB,而历史上全人类总共说过的话的数据量大约是5EB.当然,典型个人计算机硬盘的容量为TB量级,而一些大企业的数据量已经接近EB量级.

2. Velocity(高速)

   这是大数据区分于传统数据挖掘的最显著特征.根据IDC的"数字宇宙"的报告,预计到2020年,全球数据使用量将达到35.2ZB.在如此海量的数据面前,处理数据的效率就是企业的生命.

3. Variety(多样)

   这种类型的多样性也让数据被分为结构化数据和非结构化数据.相对于以往便于存储的以数据库/文本为主的结构化数据,非结构化数据越来越多,包括网络日志,音频,视频,图片,地理位置信息等,这些多类型的数据对数据的处理能力提出了更高要求.

4. Value(低价值密度)

   价值密度的高低与数据总量的大小成反比.如何快速对有价值数据"提纯"成为目前大数据背景下待解决的难题.

### 1.3 大数据应用场景

1. 物流仓储: 大数据分析系统助力商家精细化运营,提升销量,节约成本.
2. 零售: 分析用户消费习惯,为用户购买商品提供方便,从而提升商品销量.经典案例,子尿布+啤酒.
3. 旅游: 深度结合大数据能力与旅游行业需求,共建旅游产业智慧管理,智慧服务和智慧营销的未来.
4. 商品广告推荐: 给用户推荐可能喜欢的商品.
5. 保险
6. 金融
7. 房产
8. 人工智能

### 1.4 大数据发展前景

1. 党的十八大提出"实施国家大数据战略".
2. 党的十九大提出"推动互联网,大数据,人工智能和实体经济深度融合".
3. 国际数据公司IDC预测,到2020年,企业基于大数据计算分析平台的支出将突破5000亿美元.目前,我国大数据人才只有46万,未来3到5年人才缺口达150万之多.
4. 2017年北京大学,中国人民大学,北京邮电大学等25所高校成功申请开设大数据课程.
5. 大数据属于高新技术,大牛少,升职竞争小.

### 1.5 大数据部门业务流程分析

### 1.6 大数据部门组织结构

![大数据数据结构](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\1.6.1.png)

## 第2章 从Hadoop框架讨论大数据生态

### 2.1 Hadoop是什么

1. Hadoop是一个由Apache基金会所开发的分布式系统基础框架.
2. 主要解决,海量数据的存储和海量数据的分析计算问题.
3. 广义上来说,Hadoop通常是指一个更广泛的概念--Hadoop生态圈.

### 2.2 Hadoop发展历史

1. Lucene框架是Doug Cutting开创的开源软件,用Java书写代码,实现与Google类似的全文搜索功能,它提供了全文搜索引擎的架构,包括完整的查询引擎和索引引擎.

2. 2001年年底Lucene成为Apache基金会的一个子项目.

3. 对于海量数据的场景,Lucene面对与Google同样的困难,存储数据困难,检索速度慢.

4. 学习和模仿Google解决这些问题的办法: 微型版Nutch.

5. 可以说Google是Hadoop的思想之源(Google在大数据方面的三篇论文)

   ![2.2.1](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\2.2.1.png)

6. 2003年-2004年,Google公开了部分GFS和MapReduce思想的细节,以此为基础Doug Cutting等人用了2年业余时间实现了DFS和MapReduce机制,使Nutch性能飙升.

7. 2005年Hadoop作为Lucene的子项目Nutch的一部分正式引入Apache基金会.

8. 2006年3月份,Map-Reduce和Nutch Distributed File System(NDFS)分别被纳入称为Hadoop的项目中.

9. 名字来源于Doug Cutting儿子的玩具大象.

10. Hadoop就此诞生并徐速发展,标志着大数据时代的来临.

### 2.3 Hadoop三大发行版本

Hadoop三大发行版本: Apache, Cloudera, Hortonworks.

​	Apache版本是最原始(最基础)的版本,对于入门学习最好.

​	Cloudera在大型互联网企业中用的较多.

​	Hortonworks文档较好.

* Apache Hadoop
  * 官网地址:https://hadoop.apache.org/
* Cloudera Hadoop
  * 2008年成立的Cloudera是最早将Hadoop商用的公司.为合作伙伴提供Hadoop的商用解决方案,主要是包括支持,咨询服务,培训.
  * 2009年Hadoop创世人Doug Cutting也加盟了Cloudera公司.Cloudera产品主要为CDH, Cloudera Manager, Cloudera Support.
  * CDH是Cloudera的Hadoop发行版,完全开源,比Apache Hadoop在兼容性,安全性,稳定性上有所增强.
* Hortonworks Hadoop
  * 2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建.
  * 公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师,上述工程师均在2005年开始协助雅虎开发Hadoop,贡献了Hadoop80%的代码.

### 2.4 Hadoop的优势(4高)

1. 高可靠: Hadoop底层维护多个数据副本(3个),所以即使Hadoop某个计算元素或存储出现故障,也不会导致数据的丢失.
2. 高扩展性: 在集群间分配任务数据, 可方便的扩展数以千计的节点.
3. 高效性: 在MapReduce的思想下,Hadoop是并行工作的,以加快任务处理速度.
4. 高容错性: 能够自动将失败的任务重新分配.

### 2.5 Hadoop组成

![2.5.1](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\2.5.1.png)

在Hadoop1.x时代,Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度,耦合性较大,在Hadoop2.x时代,增加了Yarn.Yarn只负责资源的调度,MapReduce只负责运算.

#### 2.5.1 HDFS架构概述

1. NameNode(nn): 存储文件的元数据,如文件名,文件目录结构,文件属性(生成时间,副本数,文件权限),以及每个文件的块列表和块所在的DataNode等.
2. DataNode(dn): 在本地文件系统存储文件块数据,以及块数据的校验和.
3. Secondary NameNode(2nn): 用来监控HDFS状态的辅助后台程序,每隔一段时间获取HDFS元数据的快照

#### 2.5.2 YARN架构

1. ResourceManager(RM) 主要作用如下

   1. 处理客户端请求
   2. 监控NodeManager
   3. 启动或监控ApplicationMaster
   4. 资源的分配和调度

2. NodeManager(NM)主要作用如下

   1. 管理单个节点上的资源
   2. 处理来自ResourceManager的命令
   3. 处理来自ApplicationMaster的命令

3. ApplicationMaster(AM)作用如下

   1. 负责数据的切分
   2. 为应用程序申请资源并分配给内部的任务
   3. 任务的监控与容错

4. Container

   ​	Container是YARN中的资源抽象,它封装了某个节点上的多维度资源,如内存,CPU,磁盘,网络等.

   ![2.5.2.1](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\2.5.2.1.png)

#### 2.5.3 MapReduce架构概述

MapReduce将即算过程分为两个阶段: Map和Reduce

1. Map阶段并行处理输入数据
2. Reduce阶段对Map结果进行汇合

### 2.6大数据技术生态体系

![2.6.1](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\2.6.1.png)

### 2.7 推荐系统项目框架

![2.7.1](C:\Users\Passenger\Desktop\LinuY\Note\Java\images\hadoop\2.7.1.png)

## 第3章 Hadoop运行环境搭建

1. 搭载linux系统环境

2. 创建一个拥有sudo权限的用户

3. 创建/opt/software 和 /opt/module 文件夹

   ```bash
   mkdir /opt/software /opt/module
   ```

4.  将这两个文件夹所有者修改为当前用户

   ```bash
   chown passenger:passenger /opt/module /opt/software
   ```

5. 复制jdk,hadoop压缩文件到虚拟机中

   ```bash
   scp passenger@PassengerDellXps:/mnt/c/Users/Passenger/Downloads/jre-8u281-linux-x64.tar.gz /opt/software/
   
   scp passenger@PassengerDellXps:/mnt/c/Users/Passenger/Downloads/hadoop-3.2.2.tar.gz /opt/software/
   ```

6. 解压两个文件

   ```bash
   tar -zxvf jdk-8u281-linux-x64.tar.gz -C /opt/module
   tar -zxvf hadoop-3.2.2.tar.gz -C /opt/module
   ```

7. 添加环境变量

   ```bash
   vim /etc/profile
   # JAVA_HOME
   export JAVA_HOME=/opt/module/jdk1.8.0_281
   export $PATH=$PATH:$JAVA_HOME/bin
   
   # HADOOP_HOME
   export HADOOP_HOME=/opt/module/hadoop.3.2.2
   export $PATH=$PATH:$HADOOP_HOME/bin
   export $PATH=$PATH:$HADOOP_HOME/sbin
   ```

## 第4章 Hadoop运行模式

Hadoop运行模式包括: 本地模式,伪分布式模式以及完全分布式模式

### 4.1 本地运行模式

1. 配置环境

   1. 安装ssh和pdsh

      ```bash
      sudo pacman -S ssh
      git clone https://aur.archlinux.org/pdsh.git
      scp passenger@PassengerDellXps:/mnt/c/Users/Passenger/Downloads/pdsh-2.34.tar.gz
      tar -zxvf pdsh-2.34.tar.gz -C /opt/module/
      cd /opt/module/pdsh-2.34
      cp pdsh/PKGBUILD ./PKGBUILD
      makepkg
      ```

2. 运行example程序

   ```bash
   cd /opt/module/hadoop-3.2.2
   mkdir input
   cp etc/hadoop/*.xml input
   hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-example-3.2.2.jar grep input output 'dfs[a-z.]+'
   # output必须原本不存在
   cat output/*
   ```

   

### 4.2 伪分布式运行模式

#### 4.2.1 启动HDFS并运行MapReduce程序

1. 分析

   1. 配置集群
   2. 启动,测试集群增,删,查
   3. 执行wordcount案例

2. 执行步骤

   1. 配置集群

      1. 配置hadoop-env.sh

         ```bash
         export JAVA_HOME=/opt/module/jdk1.8.0_281
         ```
         
      2. 配置core-site.xml

         ```xml
         <configuration>
             <property>
                 <name>fs.defaultFS</name>
                 <value>hdfs://archlinux134:9000</value>
             </property>
         </configuration>
         ```

      3. 配置hdfs-site.xml

         ```xml
         <configuration>
             <property>
                 <name>dfs.replication</name>
                 <value>1</value>
             </property>
             <property>
                 <name>dfs.namenode.http-address</name>
                 <value>archlinux134:50070</value>
             </property>
         </configuration>
         ```

   2. 启动集群

      1. 格式化NameNode(第一次启动时格式化,以后就不要总格式化)

         ```bash
         hdfs namenode -format
         ```

      2. 启动namenode

         ```bash
         hdfs --daemon start namenode
         ```

      3. 启动datanode

         ```bash
         hdfs --daemon start datanode
         ```

   3. 查看集群

      1. 查看是否启动成功

         ```bash
         jps
         ```

         jps是JDK中的命令,不是linux命令.不安装JDK不能使用jps

      2. web端查看HDFS文件系统

         ```url
         http://archlinux134:50070/dfshealth.html#tab-overview
         ```

      3. 查看日志

         ```bash
         cat logs/*.log
         ```

      4. 操作集群

         1. 在HDFS文件系统上创建一个input文件夹

            ```bash
            hdfs dfs -mkdir -p /user/passenger/input
            ```

         2. 
